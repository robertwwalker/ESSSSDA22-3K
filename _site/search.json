[
  {
    "objectID": "posts/day-5/index.html",
    "href": "posts/day-5/index.html",
    "title": "Day 5: Equation Balance to Wrap Up Week 1",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-5/index.html#equation-balance",
    "href": "posts/day-5/index.html#equation-balance",
    "title": "Day 5: Equation Balance to Wrap Up Week 1",
    "section": "Equation Balance",
    "text": "Equation Balance\nThe very recent article by Pickup and Kellstedt forms the basis for summary remarks on time series and a useful transition into the study of multiple time series formally for week two.\nThe lingering issue that does not get adequate treatment owing to time is fractional integration methods. Indeed, the article by Lebo and Grant (2016) summarising the issues in the 2016 special issue is worth digesting."
  },
  {
    "objectID": "posts/day-2/index.html",
    "href": "posts/day-2/index.html",
    "title": "Day 2: Time Series, Stationarity, and ARIMA Models",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-2/index.html#simulating-arima-processes",
    "href": "posts/day-2/index.html#simulating-arima-processes",
    "title": "Day 2: Time Series, Stationarity, and ARIMA Models",
    "section": "Simulating ARIMA processes",
    "text": "Simulating ARIMA processes\nWe want to simulate data under an ARIMA (p, d, q) model. arima.sim wants inputs as a list where the expected length of the ar and ma vectors that will hold the actual values of the ar and ma parameters. Here, I ask for a series that is I(1) with a first-order ar=0.1 and a first-order ma=-0.5. Let me start by generating it and plotting the time series.\n\nlibrary(fpp3)\n\n── Attaching packages ──────────────────────────────────────────── fpp3 0.4.0 ──\n\n\n✔ tibble      3.1.8     ✔ tsibble     1.1.1\n✔ dplyr       1.0.9     ✔ tsibbledata 0.4.0\n✔ tidyr       1.2.0     ✔ feasts      0.2.2\n✔ lubridate   1.8.0     ✔ fable       0.3.1\n✔ ggplot2     3.3.6     \n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()    masks base::date()\n✖ dplyr::filter()      masks stats::filter()\n✖ tsibble::intersect() masks base::intersect()\n✖ tsibble::interval()  masks lubridate::interval()\n✖ dplyr::lag()         masks stats::lag()\n✖ tsibble::setdiff()   masks base::setdiff()\n✖ tsibble::union()     masks base::union()\n\nn <- 100\nmy.data <- data.frame(\n  x=arima.sim(n = n, \n              model=list(order = c(1, 1, 1), ar=c(0.7), ma=c(-0.5)), n.start=20), \n  dtime = seq(1,n+1))\nlibrary(magrittr)\n\n\nAttaching package: 'magrittr'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\nmy.data %<>% as_tsibble(index=dtime) \nmy.data %>% autoplot() + labs(title=\"A (1, 1, 1) Series\", x=\"Time\")\n\nPlot variable not specified, automatically selected `.vars = x`\n\n\n\n\n\nNow I want to display the ACF and PACF in levels.\n\nlibrary(patchwork)\n{my.data %>% ACF(x, lag_max=20) %>% \n    autoplot() } + \n  {my.data %>% PACF(x, lag_max=20) %>% \n      autoplot() }\n\n\n\n\nFinally, let me display the ACF and PACF with differenced data.\n\n{my.data %>% ACF(diff(x), lag_max=20) %>% \n    autoplot() } + \n  {my.data %>% PACF(diff(x), lag_max=20) %>% \n      autoplot() }"
  },
  {
    "objectID": "posts/day-2/index.html#nonsense-regressions-of-i1-series",
    "href": "posts/day-2/index.html#nonsense-regressions-of-i1-series",
    "title": "Day 2: Time Series, Stationarity, and ARIMA Models",
    "section": "Nonsense Regressions of I(1) Series",
    "text": "Nonsense Regressions of I(1) Series"
  },
  {
    "objectID": "posts/day-2/index.html#an-example-of-time-series-troubles",
    "href": "posts/day-2/index.html#an-example-of-time-series-troubles",
    "title": "Day 2: Time Series, Stationarity, and ARIMA Models",
    "section": "An Example of Time Series Troubles",
    "text": "An Example of Time Series Troubles\nLet me do this with a relatively simple regression. Two variables:\n\\[ y = \\alpha + \\beta x + \\epsilon \\]\nBoth are generated randomly. Here’s a basic plot.\n\ny <- cumsum(rnorm(100))\nx <- cumsum(rnorm(100))\nplot(x=seq(1:100), y=y, type=\"l\", col=\"red\", ylim=c(-15,15))\nlines(x=seq(1:100), y=x, col=\"blue\")\n\n\n\n\nEach time series contains 100 observations. Because both x and y are random, the slopes should be 0, 95% of the time with 95% confidence because there is no underlying relationship. In practice, let’s look at the distribution of p-values for the probability of no relationship.\n\nSR <- function(n) {\n  Results <- NULL\n  for(i in 1:n) {\ny <- cumsum(rnorm(100))\nx <- cumsum(rnorm(100))\nResult <- summary(lm(y~x))$coefficients[2,4]\nResults <- append(Result,Results)\n  }\n  Results\n}\n\nI replicate the process of random x and random y 1000 times and show the p-values below. Because they are random, approximately 95% should be greater than 0.05.\n\nRes1 <- SR(1000)\nplot(density(Res1), main=\"Distribution of p-values from Trending x\")\n\n\n\n\nIn practice,\n\ntable(Res1 > 0.05)\n\n\nFALSE  TRUE \n  779   221 \n\n\nThe above table should show about 950 TRUE and 50 FALSE but because each is trended and they share variation from trend, the actual frequency of rejecting the claim of no relationship is far more common than 5%."
  },
  {
    "objectID": "posts/day-2/index.html#arima-models-with-government-popularity",
    "href": "posts/day-2/index.html#arima-models-with-government-popularity",
    "title": "Day 2: Time Series, Stationarity, and ARIMA Models",
    "section": "ARIMA Models with Government Popularity",
    "text": "ARIMA Models with Government Popularity\n\nlibrary(fpp3)\nlibrary(haven)\nbr7983 <- read_dta(url(\"https://github.com/robertwwalker/Essex-Data/raw/main/br7983.dta\")) %>% \n  mutate(month = as.character(month)) %>% \n  mutate(month = paste0(\"19\",month, sep=\"\")) %>% \n  mutate(date = yearmonth(month, format=\"%Y%m\"))\nbr7983 <- br7983 %>% as_tsibble(index=date) \nbr7983 %>% autoplot(govpopl) + hrbrthemes::theme_ipsum() + labs(y=\"logged Government Popularity\")"
  },
  {
    "objectID": "posts/day-2/index.html#time-series-features",
    "href": "posts/day-2/index.html#time-series-features",
    "title": "Day 2: Time Series, Stationarity, and ARIMA Models",
    "section": "Time Series Features",
    "text": "Time Series Features\n\nbr7983 %>% gg_tsdisplay(govpopl, plot_type = \"partial\")\n\n\n\n\nlibrary(haven)\n# To install TSA, it works in three steps.\n# Link to package\n# https://cran.r-project.org/web/packages/TSA/index.html\n# The archive for the package is:\n# https://cran.r-project.org/src/contrib/Archive/TSA/\n# I grabbed the most recent one.\n# Then I used the RStudio: Tools > Install Packages > From a local archive\n# And installed it.\n# It had dependency chains to fix.\n# Those can be fixed with\n# install.packages(c(\"leaps\", \"locfit\", \"mgcv\"))\n\nlibrary(TSA)\n# Replicating the abrupt permanent in April\narimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xreg=br7983$flandd)\n\n\nCall:\narimax(x = br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), \n    xreg = br7983$flandd)\n\nCoefficients:\n        sma1  intercept    xreg\n      0.3430     0.0015  0.0687\ns.e.  0.1347     0.0184  0.0950\n\nsigma^2 estimated as 0.009071:  log likelihood = 43.57,  aic = -81.15\n\n\n\n# Replicating the abrupt permanent in May\narimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xreg=br7983$flanddlag1)\n\n\nCall:\narimax(x = br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), \n    xreg = br7983$flanddlag1)\n\nCoefficients:\n        sma1  intercept    xreg\n      0.2668    -0.0033  0.3124\ns.e.  0.1310     0.0153  0.0842\n\nsigma^2 estimated as 0.007019:  log likelihood = 49.7,  aic = -93.41\n\n\n\n# Replicating the gradual permanent April\narimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xtransf = br7983$flandd, transfer = list(c(1,0)))\n\n\nCall:\narimax(x = br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), \n    xtransf = br7983$flandd, transfer = list(c(1, 0)))\n\nCoefficients:\n        sma1  intercept  T1-AR1  T1-MA0\n      0.3930    -0.0080  0.6479  0.1885\ns.e.  0.1251     0.0185  0.1528  0.0718\n\nsigma^2 estimated as 0.007946:  log likelihood = 46.6,  aic = -85.2\n\n\n\n# Replicating the gradual permanent May\n# Does not work; degrees of freedom?\n# arimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xtransf = br7983$flanddlag1, transfer = list(c(1,0)))\n# Falklands - gradual temporary (pulse decay) effect - May 1982\n# Does not work; degrees of freedom?\n# arimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xtransf = br7983$flanddlag1, transfer = list(c(1,1)))\n# These are fairly demanding [of the data] models.\narimax(br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), xtransf = br7983$flandd, transfer = list(c(1,0)))\n\n\nCall:\narimax(x = br7983$govpopld, seasonal = list(order = c(0, 0, 1), period = 4), \n    xtransf = br7983$flandd, transfer = list(c(1, 0)))\n\nCoefficients:\n        sma1  intercept  T1-AR1  T1-MA0\n      0.3930    -0.0080  0.6479  0.1885\ns.e.  0.1251     0.0185  0.1528  0.0718\n\nsigma^2 estimated as 0.007946:  log likelihood = 46.6,  aic = -85.2\n\n\n\nARIMA\nStata covers this in the following link.\nwpi1 <- read_stata(url(\"http://www.stata-press.com/data/r12/wpi1.dta\"))\nwpi1$date <- yearquarter(wpi1$t, fiscal_start = 1)-40\n\nload(url(\"https://github.com/robertwwalker/Essex-Data/raw/main/wpi1.RData\"))\nwpi1 %>% as_tsibble(index=date) %>% gg_tsdisplay(ln_wpi, plot_type = \"partial\") + labs(title=\"Log WPI\")\n\n\n\n\n\n\nStata\narima wpi, arima(1,1,1)\n\n\nR\n\nwpi1 %>% as_tsibble(index=date) %>% \n  model(arima = ARIMA(wpi ~ 1 + pdq(1,1,1) + PDQ(0,0,0))) %>% \n  report()\n\nSeries: wpi \nModel: ARIMA(1,1,1) w/ drift \n\nCoefficients:\n         ar1      ma1  constant\n      0.8742  -0.4120    0.0943\ns.e.  0.0637   0.1221    0.0367\n\nsigma^2 estimated as 0.5388:  log likelihood=-135.35\nAIC=278.7   AICc=279.04   BIC=289.95\n\n\nThe help for ARIMA explains the alternative parameterization.\n\n# Using stats::arima\narima(diff(wpi1$wpi), order=c(1,0,1), include.mean = TRUE)\n\n\nCall:\narima(x = diff(wpi1$wpi), order = c(1, 0, 1), include.mean = TRUE)\n\nCoefficients:\n         ar1      ma1  intercept\n      0.8742  -0.4120     0.7499\ns.e.  0.0637   0.1221     0.2921\n\nsigma^2 estimated as 0.5257:  log likelihood = -135.35,  aic = 276.7"
  },
  {
    "objectID": "posts/day-2/index.html#seasonal",
    "href": "posts/day-2/index.html#seasonal",
    "title": "Day 2: Time Series, Stationarity, and ARIMA Models",
    "section": "Seasonal",
    "text": "Seasonal\narima D.ln_wpi, ar(1) ma(1 4)\n\nwpi1 %>% as_tsibble(index=date) %>% \n  model(arima = ARIMA(ln_wpi ~ 1 + pdq(1,1,1) + PDQ(0,0,1))) %>% \n  report()\n\nSeries: ln_wpi \nModel: ARIMA(1,1,1)(0,0,1)[4] w/ drift \n\nCoefficients:\n         ar1      ma1    sma1  constant\n      0.8289  -0.4252  0.2403    0.0019\ns.e.  0.0854   0.1374  0.0959    0.0007\n\nsigma^2 estimated as 0.0001144:  log likelihood=385.27\nAIC=-760.53   AICc=-760.02   BIC=-746.47\n\n\nThere are also bits about seasonal arima – sarima – and arimax but Stata is fundamentally limited here.\n\nwpi1 %>% as_tsibble(index=date) %>% \n  model(arima = ARIMA(ln_wpi ~ 1 + pdq(1,1,1) + PDQ(0,0,1))) %>% \n  gg_tsresiduals()\n\n\n\n\nThat works."
  },
  {
    "objectID": "posts/day-3/index.html",
    "href": "posts/day-3/index.html",
    "title": "Day 3: Dynamic Linear, ADL Models, and VARs",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-3/index.html#dynamic-regression",
    "href": "posts/day-3/index.html#dynamic-regression",
    "title": "Day 3: Dynamic Linear, ADL Models, and VARs",
    "section": "Dynamic Regression",
    "text": "Dynamic Regression\nRegression techniques can be reexamined through the lens of dynamic linear models and systems of linear equations. Whether autoregressive distributed lag models or VAR systems and structural time series, regression approaches to time series almost inevitably culminate in thinking about causation as conceived by Clive Granger – Granger causality.\nToday we cover chapters 3 and 4 in TSASS spanning dynamic regression models and dynamic systems. We will start with dynamic regression models by detailing how they are specified and interpreted with distributed lag and autoregressive distributed lag [ADL] models. We also examine the crucial issue of consistency before turning to structural time series models for multiple equations and their counterparts – VARs."
  },
  {
    "objectID": "posts/day-3/index.html#vars",
    "href": "posts/day-3/index.html#vars",
    "title": "Day 3: Dynamic Linear, ADL Models, and VARs",
    "section": "VARs",
    "text": "VARs\nWe will start with some data on lung deaths from Australia.\nlibrary(forecast)\nmdeaths\nfdeaths\nsave(mdeaths, fdeaths, file = \"./img/LungDeaths.RData\")\nuse \"https://github.com/robertwwalker/Essex-Data/raw/main/Lung-Deaths.dta\"\n\nlibrary(hrbrthemes); library(fpp3)\nload(url(\"https://github.com/robertwwalker/Essex-Data/raw/main/LungDeaths.RData\"))\nMales <- mdeaths; Females <- fdeaths\nLung.Deaths <- cbind(Males, Females) %>% as_tsibble()\nLung.Deaths %>% autoplot() + theme_ipsum_rc() + labs(y=\"Lung Deaths\", x=\"Month [1M]\", title=\"Lung Deaths among Males and Females\") + guides(color=\"none\")\n\n\n\n\n\nlung_deaths <- cbind(mdeaths, fdeaths) %>%\n  as_tsibble(pivot_longer = FALSE)\nlung_deaths <- cbind(mdeaths, fdeaths) %>%\n  as_tsibble(pivot_longer = FALSE)\nfit <- lung_deaths %>%\n  model(VAR(vars(mdeaths, fdeaths) ~ AR(3)))\nreport(fit)\n\nSeries: mdeaths, fdeaths \nModel: VAR(3) w/ mean \n\nCoefficients for mdeaths:\n      lag(mdeaths,1)  lag(fdeaths,1)  lag(mdeaths,2)  lag(fdeaths,2)\n              0.6675          0.8074          0.3677         -1.4540\ns.e.          0.3550          0.8347          0.3525          0.8088\n      lag(mdeaths,3)  lag(fdeaths,3)  constant\n              0.2606         -1.1214  538.7817\ns.e.          0.3424          0.8143  137.1047\n\nCoefficients for fdeaths:\n      lag(mdeaths,1)  lag(fdeaths,1)  lag(mdeaths,2)  lag(fdeaths,2)\n              0.2138          0.4563          0.0937         -0.3984\ns.e.          0.1460          0.3434          0.1450          0.3328\n      lag(mdeaths,3)  lag(fdeaths,3)  constant\n              0.0250          -0.315  202.0027\ns.e.          0.1409           0.335   56.4065\n\nResidual covariance matrix:\n         mdeaths  fdeaths\nmdeaths 58985.95 22747.94\nfdeaths 22747.94  9983.95\n\nlog likelihood = -812.35\nAIC = 1660.69   AICc = 1674.37  BIC = 1700.9\n\n\nvar mdeaths fdeaths, lags(1 2 3)  \n\nfit2 <- lung_deaths %>%\n  model(VAR(vars(mdeaths, fdeaths) ~ AR(2)))\nreport(fit2)\n\nSeries: mdeaths, fdeaths \nModel: VAR(2) w/ mean \n\nCoefficients for mdeaths:\n      lag(mdeaths,1)  lag(fdeaths,1)  lag(mdeaths,2)  lag(fdeaths,2)  constant\n              0.9610          0.3340          0.1149         -1.3379  443.8492\ns.e.          0.3409          0.8252          0.3410          0.7922  124.4608\n\nCoefficients for fdeaths:\n      lag(mdeaths,1)  lag(fdeaths,1)  lag(mdeaths,2)  lag(fdeaths,2)  constant\n              0.3391          0.2617         -0.0601         -0.2691  145.0546\ns.e.          0.1450          0.3510          0.1450          0.3369   52.9324\n\nResidual covariance matrix:\n         mdeaths  fdeaths\nmdeaths 62599.51 24942.79\nfdeaths 24942.79 11322.70\n\nlog likelihood = -833.17\nAIC = 1694.35   AICc = 1701.98  BIC = 1725.83\n\n\nvar mdeaths fdeaths, lags(1 2)  \nGranger causation wants a non-tidy format. I will use the conventional VAR syntax from vars that wants the collection of endogenous variables as inputs by themselves in a matrix form. We can also specify exogenous variable for such systems with their data matrix in the argument exogen=....\n\nlibrary(bruceR)\n\n\nbruceR (version 0.8.8)\nBRoadly Useful Convenient and Efficient R functions\n\nPackages also loaded:\n√ dplyr         √ emmeans       √ ggplot2\n√ tidyr         √ effectsize    √ ggtext\n√ stringr       √ performance   √ cowplot\n√ forcats       √ lmerTest      √ see\n√ data.table\n\nMain functions of `bruceR`:\ncc()            Describe()  TTEST()\nadd()           Freq()      MANOVA()\n.mean()         Corr()      EMMEANS()\nset.wd()        Alpha()     PROCESS()\nimport()        EFA()       model_summary()\nprint_table()   CFA()       lavaan_summary()\n\nhttps://psychbruce.github.io/bruceR/\n\nVarmf <- vars::VAR(lung_deaths[,c(\"mdeaths\",\"fdeaths\")], p=3, type=\"const\")\ngranger_causality(Varmf)\n\n\nGranger Causality Test (Multivariate)\n\nF test and Wald χ² test based on VAR(3) model:\n────────────────────────────────────────────────────────────────\n                          F df1 df2     p     Chisq df     p    \n────────────────────────────────────────────────────────────────\n ------------------                                             \n mdeaths <= fdeaths    1.93   3  62  .134      5.80  3  .122    \n mdeaths <= ALL        1.93   3  62  .134      5.80  3  .122    \n ------------------                                             \n fdeaths <= mdeaths    1.20   3  62  .316      3.61  3  .307    \n fdeaths <= ALL        1.20   3  62  .316      3.61  3  .307    \n────────────────────────────────────────────────────────────────\n\n\nvargranger\n\nfit %>%\n  fabletools::forecast(h=12) %>%\n  autoplot(lung_deaths)\n\n\n\n\n\nFemale\n\nlung_deaths %>%\nmodel(VAR(vars(mdeaths, fdeaths) ~ AR(3))) %>%\n  residuals() %>% \n  pivot_longer(., cols = c(mdeaths,fdeaths)) %>% \n  filter(name==\"fdeaths\") %>% \n  as_tsibble(index=index) %>% \n  gg_tsdisplay(plot_type = \"partial\") + labs(title=\"Female residuals\")\n\n\n\n\n\n\nMale\n\nlung_deaths %>%\nmodel(VAR(vars(mdeaths, fdeaths) ~ AR(3))) %>%\n  residuals() %>% \n  pivot_longer(., cols = c(mdeaths,fdeaths)) %>% \n  filter(name==\"mdeaths\") %>% \n  as_tsibble(index=index) %>% \n  gg_tsdisplay(plot_type = \"partial\") + labs(title=\"Male residuals\")"
  },
  {
    "objectID": "posts/day-3/index.html#easy-impulse-response",
    "href": "posts/day-3/index.html#easy-impulse-response",
    "title": "Day 3: Dynamic Linear, ADL Models, and VARs",
    "section": "Easy Impulse Response",
    "text": "Easy Impulse Response\nWhat happens if I shock one of the series; how does it work through the system?\nThe idea behind an impulse-response is core to counterfactual analysis with time series. What does our future world look like and what predictions arise from it and the model we have deployed?\nWhether VARs or dynamic linear models or ADL models, these are key to interpreting a model in the real world.\n\nMales\n\nVARMF <- cbind(Males,Females)\nmod1 <- vars::VAR(VARMF, p=3, type=\"const\")\nplot(vars::irf(mod1, boot=TRUE, impulse=\"Males\"))\n\n\n\n\n\n\nFemales\n\nplot(vars::irf(mod1, boot=TRUE, impulse=\"Females\"))"
  },
  {
    "objectID": "posts/day-4/index.html",
    "href": "posts/day-4/index.html",
    "title": "Day 4: Cointegration",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-4/index.html#a-replication",
    "href": "posts/day-4/index.html#a-replication",
    "title": "Day 4: Cointegration",
    "section": "A replication",
    "text": "A replication\nThis is an example with an ECM from a model presented by DeBoef and Keele in their excellent paper “Taking Time Seriously: Dynamic Regression.” The data come from a paper Gilmour and Wolbrecht.\n\nlibrary(haven); library(tidyverse); library(fpp3)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\n── Attaching packages ──────────────────────────────────────────── fpp3 0.4.0 ──\n\n\n✔ lubridate   1.8.0     ✔ feasts      0.2.2\n✔ tsibble     1.1.1     ✔ fable       0.3.1\n✔ tsibbledata 0.4.0     \n\n\n── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ──\n✖ lubridate::date()    masks base::date()\n✖ dplyr::filter()      masks stats::filter()\n✖ tsibble::intersect() masks base::intersect()\n✖ tsibble::interval()  masks lubridate::interval()\n✖ dplyr::lag()         masks stats::lag()\n✖ tsibble::setdiff()   masks base::setdiff()\n✖ tsibble::union()     masks base::union()\n\ndgw.data <- read_stata(\"https://github.com/robertwwalker/Essex-Data/raw/main/dgw.dta\")\ndgw.data <- dgw.data %>% filter(!is.na(year))\ndgw.data <- dgw.data %>% mutate(date = paste0(year,\" Q\",quarter, sep=\"\")) %>% mutate(dateQ = yearquarter(date))\ndgw.ts <- dgw.data %>% as_tsibble(index=dateQ)\n# A dynamic linear model\ndgw.ts %>% model(TSLM(capp~lag(capp,1)+econexp+nytavg+kg+hb+vetoes+override+intrasum+mbills)) %>% report()\n\nSeries: capp \nModel: TSLM \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.1137 -1.3908 -0.1014  1.5446  7.0873 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   9.37793    3.33043   2.816  0.00634 ** \nlag(capp, 1)  0.79605    0.05166  15.409  < 2e-16 ***\neconexp       0.07173    0.03090   2.321  0.02323 *  \nnytavg        0.20716    0.06982   2.967  0.00413 ** \nkg           -1.29097    1.08646  -1.188  0.23881    \nhb           -4.68564    1.69975  -2.757  0.00746 ** \nvetoes        0.24382    0.08898   2.740  0.00781 ** \noverride     -0.99198    0.55252  -1.795  0.07697 .  \nintrasum     -0.16907    0.12199  -1.386  0.17021    \nmbills       -0.43939    0.28270  -1.554  0.12469    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.976 on 69 degrees of freedom\nMultiple R-squared: 0.885,  Adjusted R-squared: 0.8699\nF-statistic: 58.97 on 9 and 69 DF, p-value: < 2.22e-16\n\n\n\ndgw.ts %>% model(TSLM(capp~lag(capp,1)+p_prap+econexp+nytavg+kg+hb+vetoes+override+intrasum+mbills)) %>% report()\n\nSeries: capp \nModel: TSLM \n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.4892 -1.3161 -0.1978  1.7633  6.3624 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  10.13865    3.38461   2.996  0.00382 ** \nlag(capp, 1)  0.77084    0.05585  13.803  < 2e-16 ***\np_prap        0.04708    0.04024   1.170  0.24610    \neconexp       0.08161    0.03195   2.554  0.01290 *  \nnytavg        0.20342    0.06971   2.918  0.00477 ** \nkg           -1.61049    1.11745  -1.441  0.15411    \nhb           -4.87343    1.70280  -2.862  0.00559 ** \nvetoes        0.24012    0.08880   2.704  0.00865 ** \noverride     -0.96229    0.55163  -1.744  0.08560 .  \nintrasum     -0.14809    0.12298  -1.204  0.23267    \nmbills       -0.46652    0.28290  -1.649  0.10375    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.968 on 68 degrees of freedom\nMultiple R-squared: 0.8872, Adjusted R-squared: 0.8706\nF-statistic:  53.5 on 10 and 68 DF, p-value: < 2.22e-16\n\n\n\ndgw.ts %>% model(TSLM(capp~lag(capp, 1)+p_prap+lag(p_prap, 1)+econexp+lag(econexp,1)+nytavg+lag(nytavg, 1)+kg+hb+vetoes+override+intrasum+mbills)) %>% gg_tsresiduals()\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\nWarning: Removed 1 rows containing non-finite values (stat_bin).\n\n\n\n\n\nuse \"https://github.com/robertwwalker/Essex-Data/raw/main/dgw.dta\", clear\n* These data have already been time set:\ntsset\n* The dependent variable in this example is Congressional Approval\n*Table 2\nreg capp l.capp econexp nytavg kg hb vetoes override intrasum mbill \nbgodfrey, lag(1 2 3)\n*Table 2 with Pres. Approval\nreg capp l.capp p_prap econexp nytavg kg hb vetoes override intrasum mbill \nbgodfrey, lag(1 2 3)\n* An Alternate Measure\n* ADL\nreg capp l.capp p_prap l.p_prap econexp l.econexp nytavg l.nytavg kg hb vetoes override intrasum mbill \nfitstat\nbgodfrey, lag(1 2 3)\nreg capp l.capp p_prap l.p_prap econexp l.econexp nytavg l.nytavg l2.nytavg kg hb vetoes override intrasum mbill \nfitstat\ntest l.p_prap \n*ECM\nreg d.capp l.capp d.p_prap l.p_prap d.econexp l.econexp d.nytavg l.nytavg kg hb vetoes override intrasum mbill \nbgodfrey, lag(1 2 3)\n*Bewley\nivreg capp p_prap d.p_prap econexp d.econexp nytavg d.nytavg kg hb vetoes override intrasum mbill (d.capp = l.capp p_prap l.p_prap econexp l.econexp nytavg l.nytavg)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome!",
    "section": "",
    "text": "I hope you are ready!\nIn the next two weeks we will set forth as comprehensive a treatment as we can in time series and panel data in ten sessions. With coffee in hand and the computer getting ready, let’s dig in!\n\nA brief summary for the Instructor’s Presentation\n\nWeek 1: Time Series\n\nStationarity and Unit Roots\nARMA structures\nDynamic Linear Models and their Interpretation\nCointegration topics\nEquation balance and recent controversies\n\nWeek 2: Panel Data\n\nFixed and random effects and Within/Between\nSTADL Up!\nMissing data\nGLM Extensions of Panel Models\nCausal Inference in Panel Data [TWFE/DID]"
  },
  {
    "objectID": "posts/welcome/index.html#topics-of-interest-cut-by-time",
    "href": "posts/welcome/index.html#topics-of-interest-cut-by-time",
    "title": "Welcome!",
    "section": "Topics of Interest Cut by Time",
    "text": "Topics of Interest Cut by Time\nWe will read selections from a broader controversy in Political Analysis on Time Series and error correction models; the full list of papers can be found here as a large part of the Winter 2016 issue 24(1).\nThere is a digital special issue of Political Analysis on Regression Discontinuity and Time Series Cross-Section data. For day 6 of the class, the paper by Plumper and Troeger (2019) about fixed effects regression is definitely worth considering.\nFactor augmented dynamic panel data models get an interesting treatment in Dynamic Panel Analysis under Cross-Sectional Dependence by Khusrav Gaibulloev, Todd Sandler and Donggyu Sul"
  },
  {
    "objectID": "posts/day-8/index.html",
    "href": "posts/day-8/index.html",
    "title": "Day 8: Panel Models for Limited Outcomes",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-1/index.html",
    "href": "posts/day-1/index.html",
    "title": "Day 1",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-1/index.html#basic-r-commands",
    "href": "posts/day-1/index.html#basic-r-commands",
    "title": "Day 1",
    "section": "Basic R commands",
    "text": "Basic R commands\n\nlibrary(haven); library(kableExtra)\nHR.Data <- read_dta(url(\"https://github.com/robertwwalker/DADMStuff/raw/master/ISQ99-Essex.dta\"))\nlibrary(skimr)\nskim(HR.Data) %>% kable() %>% scroll_box(width=\"80%\", height=\"50%\")\n\n\n\n \n  \n    skim_type \n    skim_variable \n    n_missing \n    complete_rate \n    numeric.mean \n    numeric.sd \n    numeric.p0 \n    numeric.p25 \n    numeric.p50 \n    numeric.p75 \n    numeric.p100 \n    numeric.hist \n  \n \n\n  \n    numeric \n    IDORIGIN \n    0 \n    1.0000000 \n    446.7178771 \n    243.1931782 \n    2.00 \n    290.000 \n    435.000 \n    640.00 \n    990.00 \n    ▆▇▇▆▂ \n  \n  \n    numeric \n    YEAR \n    0 \n    1.0000000 \n    1984.5000000 \n    5.1889328 \n    1976.00 \n    1980.000 \n    1984.500 \n    1989.00 \n    1993.00 \n    ▇▆▇▆▇ \n  \n  \n    numeric \n    AI \n    1061 \n    0.6707014 \n    2.7533549 \n    1.0752989 \n    1.00 \n    2.000 \n    3.000 \n    3.00 \n    5.00 \n    ▃▇▇▃▂ \n  \n  \n    numeric \n    SD \n    587 \n    0.8178150 \n    2.2406072 \n    1.1303528 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▆▂▁ \n  \n  \n    numeric \n    POLRT \n    382 \n    0.8814401 \n    3.8095070 \n    2.2230297 \n    1.00 \n    2.000 \n    3.000 \n    6.00 \n    7.00 \n    ▇▂▂▁▇ \n  \n  \n    numeric \n    MIL2 \n    382 \n    0.8814401 \n    0.2725352 \n    0.4453421 \n    0.00 \n    0.000 \n    0.000 \n    1.00 \n    1.00 \n    ▇▁▁▁▃ \n  \n  \n    numeric \n    LEFT \n    393 \n    0.8780261 \n    0.1763874 \n    0.3812168 \n    0.00 \n    0.000 \n    0.000 \n    0.00 \n    1.00 \n    ▇▁▁▁▂ \n  \n  \n    numeric \n    BRIT \n    290 \n    0.9099938 \n    0.3553888 \n    0.4787126 \n    0.00 \n    0.000 \n    0.000 \n    1.00 \n    1.00 \n    ▇▁▁▁▅ \n  \n  \n    numeric \n    PCGNP \n    443 \n    0.8625078 \n    3591.6509536 \n    5698.3554010 \n    52.00 \n    390.000 \n    1112.000 \n    3510.00 \n    36670.00 \n    ▇▁▁▁▁ \n  \n  \n    numeric \n    AINEW \n    468 \n    0.8547486 \n    2.4433551 \n    1.1558005 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▇▃▂ \n  \n  \n    numeric \n    SDNEW \n    468 \n    0.8547486 \n    2.2618010 \n    1.1365604 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▆▂▁ \n  \n  \n    numeric \n    IDGURR \n    0 \n    1.0000000 \n    455.7709497 \n    246.5201369 \n    2.00 \n    290.000 \n    450.000 \n    663.00 \n    990.00 \n    ▆▇▇▇▃ \n  \n  \n    numeric \n    AILAG \n    644 \n    0.8001241 \n    2.4499612 \n    1.1479673 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▇▃▂ \n  \n  \n    numeric \n    SDLAG \n    644 \n    0.8001241 \n    2.2470908 \n    1.1156632 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▆▂▁ \n  \n  \n    numeric \n    PERCHPCG \n    618 \n    0.8081937 \n    4.6138441 \n    13.2208934 \n    -95.50 \n    -2.545 \n    4.615 \n    11.76 \n    128.57 \n    ▁▂▇▁▁ \n  \n  \n    numeric \n    PERCHPOP \n    293 \n    0.9090627 \n    2.1928815 \n    4.0424128 \n    -48.45 \n    0.910 \n    2.220 \n    2.94 \n    126.01 \n    ▁▇▁▁▁ \n  \n  \n    numeric \n    LPOP \n    115 \n    0.9643079 \n    15.4819279 \n    1.8633316 \n    11.00 \n    14.510 \n    15.590 \n    16.64 \n    20.89 \n    ▂▃▇▃▁ \n  \n  \n    numeric \n    PCGTHOU \n    443 \n    0.8625078 \n    3.5916985 \n    5.6983334 \n    0.05 \n    0.390 \n    1.110 \n    3.51 \n    36.67 \n    ▇▁▁▁▁ \n  \n  \n    numeric \n    DEMOC3 \n    793 \n    0.7538796 \n    3.6817620 \n    4.3577178 \n    0.00 \n    0.000 \n    0.000 \n    9.00 \n    10.00 \n    ▇▁▁▂▃ \n  \n  \n    numeric \n    CWARCOW \n    407 \n    0.8736809 \n    0.0920071 \n    0.2890873 \n    0.00 \n    0.000 \n    0.000 \n    0.00 \n    1.00 \n    ▇▁▁▁▁ \n  \n  \n    numeric \n    IWARCOW2 \n    380 \n    0.8820608 \n    0.0862069 \n    0.2807187 \n    0.00 \n    0.000 \n    0.000 \n    0.00 \n    1.00 \n    ▇▁▁▁▁"
  },
  {
    "objectID": "posts/day-1/index.html#more-r-summary",
    "href": "posts/day-1/index.html#more-r-summary",
    "title": "Day 1",
    "section": "More R summary",
    "text": "More R summary\nA little function that I wrote up on github.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::group_rows() masks kableExtra::group_rows()\n✖ dplyr::lag()        masks stats::lag()\n\nlibrary(plm)\n\n\nAttaching package: 'plm'\n\nThe following objects are masked from 'package:dplyr':\n\n    between, lag, lead\n\nsource(url(\"https://raw.githubusercontent.com/robertwwalker/DADMStuff/master/xtsum.R\"))\n# Be careful with the ID variable, the safest is to make it factor; this can go wildly wrong\nxtsum(IDORIGIN~., data=HR.Data) %>% kable() %>% scroll_box(width=\"80%\", height=\"50%\")\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(unit)` instead of `unit` to silence this message.\nℹ See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\nThis message is displayed once per session.\n\n\n\n\n \n  \n      \n    O.mean \n    O.sd \n    O.min \n    O.max \n    O.SumSQ \n    O.N \n    B.mean \n    B.sd \n    B.min \n    B.max \n    B.Units \n    B.t.bar \n    W.sd \n    W.min \n    W.max \n    W.SumSQ \n    Within.Ovr.Ratio \n  \n \n\n  \n    YEAR \n    1984.5 \n    5.189 \n    1976 \n    1993 \n    86725.5 \n    3222 \n    1984.5 \n    0 \n    1984.5 \n    1984.5 \n    179 \n    18 \n    5.189 \n    -8.5 \n    8.5 \n    86725.5 \n    1 \n  \n  \n    AI \n    2.753 \n    1.075 \n    1 \n    5 \n    2497.538 \n    2161 \n    2.498 \n    0.989 \n    1 \n    5 \n    173 \n    12.491 \n    0.631 \n    -2.375 \n    2.5625 \n    860.822 \n    0.345 \n  \n  \n    SD \n    2.241 \n    1.13 \n    1 \n    5 \n    3365.455 \n    2635 \n    2.241 \n    1.004 \n    1 \n    5 \n    178 \n    14.803 \n    0.624 \n    -2.666667 \n    3.0625 \n    1025.695 \n    0.305 \n  \n  \n    POLRT \n    3.81 \n    2.223 \n    1 \n    7 \n    14029.94 \n    2840 \n    3.78 \n    1.99 \n    1 \n    7 \n    179 \n    15.866 \n    0.925 \n    -4 \n    4.777778 \n    2428.552 \n    0.173 \n  \n  \n    MIL2 \n    0.273 \n    0.445 \n    0 \n    1 \n    563.058 \n    2840 \n    0.24 \n    0.377 \n    0 \n    1 \n    179 \n    15.866 \n    0.216 \n    -0.9444444 \n    0.8888889 \n    132.778 \n    0.236 \n  \n  \n    LEFT \n    0.176 \n    0.381 \n    0 \n    1 \n    410.983 \n    2829 \n    0.157 \n    0.334 \n    0 \n    1 \n    179 \n    15.804 \n    0.157 \n    -0.8888889 \n    0.8888889 \n    69.611 \n    0.169 \n  \n  \n    BRIT \n    0.355 \n    0.479 \n    0 \n    1 \n    671.685 \n    2932 \n    0.335 \n    0.473 \n    0 \n    1 \n    179 \n    16.38 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    PCGNP \n    3591.651 \n    5698.355 \n    52 \n    36670 \n    90205144379 \n    2779 \n    3449.178 \n    5049.297 \n    112.2222 \n    22653.89 \n    173 \n    16.064 \n    2278.412 \n    -12303.33 \n    16961.67 \n    14421042273 \n    0.16 \n  \n  \n    AINEW \n    2.443 \n    1.156 \n    1 \n    5 \n    3677.663 \n    2754 \n    2.379 \n    1.012 \n    1 \n    5 \n    178 \n    15.472 \n    0.622 \n    -2.388889 \n    2.944444 \n    1064.102 \n    0.289 \n  \n  \n    SDNEW \n    2.262 \n    1.137 \n    1 \n    5 \n    3556.241 \n    2754 \n    2.253 \n    1.006 \n    1 \n    5 \n    178 \n    15.472 \n    0.631 \n    -2.588235 \n    3 \n    1096.442 \n    0.308 \n  \n  \n    IDGURR \n    455.771 \n    246.52 \n    2 \n    990 \n    195747185 \n    3222 \n    455.771 \n    247.173 \n    2 \n    990 \n    179 \n    18 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    AILAG \n    2.45 \n    1.148 \n    1 \n    5 \n    3396.045 \n    2578 \n    2.402 \n    1.039 \n    1 \n    5 \n    177 \n    14.565 \n    0.609 \n    -2.411765 \n    3 \n    955.37 \n    0.281 \n  \n  \n    SDLAG \n    2.247 \n    1.116 \n    1 \n    5 \n    3207.603 \n    2578 \n    2.236 \n    0.991 \n    1 \n    5 \n    177 \n    14.565 \n    0.608 \n    -2.5 \n    3.058824 \n    952.174 \n    0.297 \n  \n  \n    PERCHPCG \n    4.614 \n    13.221 \n    -95.5 \n    128.57 \n    454983.6 \n    2604 \n    3.325 \n    6.893 \n    -36.21333 \n    15.03765 \n    168 \n    15.5 \n    12.393 \n    -92.50235 \n    114.8882 \n    399763 \n    0.879 \n  \n  \n    PERCHPOP \n    2.193 \n    4.042 \n    -48.45 \n    126.01 \n    47846.75 \n    2929 \n    2.842 \n    9.443 \n    -2.126471 \n    126.01 \n    176 \n    16.642 \n    3.018 \n    -48.12235 \n    80.69765 \n    26663.59 \n    0.557 \n  \n  \n    LPOP \n    15.482 \n    1.863 \n    11 \n    20.89 \n    10784.05 \n    3107 \n    15.488 \n    1.844 \n    11.09056 \n    20.76889 \n    177 \n    17.554 \n    0.129 \n    -0.7288889 \n    0.7311111 \n    51.883 \n    0.005 \n  \n  \n    PCGTHOU \n    3.592 \n    5.698 \n    0.05 \n    36.67 \n    90204.45 \n    2779 \n    3.449 \n    5.049 \n    0.1122222 \n    22.65389 \n    173 \n    16.064 \n    2.278 \n    -12.30333 \n    16.96167 \n    14420.95 \n    0.16 \n  \n  \n    DEMOC3 \n    3.682 \n    4.358 \n    0 \n    10 \n    46107 \n    2429 \n    3.774 \n    3.96 \n    0 \n    10 \n    155 \n    15.671 \n    1.726 \n    -7.277778 \n    7.941176 \n    7229.815 \n    0.157 \n  \n  \n    CWARCOW \n    0.092 \n    0.289 \n    0 \n    1 \n    235.17 \n    2815 \n    0.095 \n    0.245 \n    0 \n    1 \n    179 \n    15.726 \n    0.175 \n    -0.8888889 \n    0.9444444 \n    85.693 \n    0.364 \n  \n  \n    IWARCOW2 \n    0.086 \n    0.281 \n    0 \n    1 \n    223.879 \n    2842 \n    0.092 \n    0.227 \n    0 \n    1 \n    179 \n    15.877 \n    0.19 \n    -0.8888889 \n    0.9444444 \n    102.992 \n    0.46"
  },
  {
    "objectID": "posts/day-1/index.html#the-core-idea",
    "href": "posts/day-1/index.html#the-core-idea",
    "title": "Day 1",
    "section": "The Core Idea",
    "text": "The Core Idea\nIn R, this is an essential group_by calculation in the tidyverse. The within data is the overall data with group means subtracted.\n\nHR.Data %>% \n  group_by(IDORIGIN) %>% \n  mutate(DEMOC.Centered = \n           DEMOC3 - mean(DEMOC3, na.rm=TRUE)) %>%\n  filter(IDORIGIN==42) %>% \n  select(IDORIGIN, YEAR, DEMOC3, DEMOC.Centered) \n\n# A tibble: 18 × 4\n# Groups:   IDORIGIN [1]\n   IDORIGIN  YEAR DEMOC3 DEMOC.Centered\n      <dbl> <dbl>  <dbl>          <dbl>\n 1       42  1976      1         -5.11 \n 2       42  1977      1         -5.11 \n 3       42  1978      6         -0.111\n 4       42  1979      6         -0.111\n 5       42  1980      6         -0.111\n 6       42  1981      6         -0.111\n 7       42  1982      7          0.889\n 8       42  1983      7          0.889\n 9       42  1984      7          0.889\n10       42  1985      7          0.889\n11       42  1986      7          0.889\n12       42  1987      7          0.889\n13       42  1988      7          0.889\n14       42  1989      7          0.889\n15       42  1990      7          0.889\n16       42  1991      7          0.889\n17       42  1992      7          0.889\n18       42  1993      7          0.889\n\n\nIn Stata, the key is to first load and declare the data.\nuse \"https://github.com/robertwwalker/Essex-Data/raw/main/ISQ99-Essex.dta\"\ndes\n\n\n\nStata Load\n\n\nxtset denotes two key features of the data, the \\(i\\) and \\(t\\).\nxtset IDORIGIN YEAR\n\n\n\nxtset\n\n\nStata has internal capabilities for summarising and describing xt data. A between and within summary is given by xtsum\nxtsum\n\n\n\nxtsum\n\n\nThe description can be deceptive because the indices are a complete grid.\nxtdes\n\n\n\nxtdes"
  },
  {
    "objectID": "posts/day-1/index.html#qualitative-variables",
    "href": "posts/day-1/index.html#qualitative-variables",
    "title": "Day 1",
    "section": "Qualitative Variables",
    "text": "Qualitative Variables\n\nxttab\n\nBetween: How many units received each category?\nWithin: Of all observations of units that received that category at least once, what percent of observations take this value?\n\nxttab AINEW\n\n\n\nxttab\n\n\n\n\nThe Between\n\nbetween.tally <- function(x) {\nHR.Data %>% select(IDORIGIN, AINEW) %>% filter(AINEW==x) %$% table(IDORIGIN) %>% length()\n}\nsapply(c(1:5), function(x) {between.tally(x)})\n\n[1]  96 121 113  86  43\n\n\n\n\nxttrans\nA first-order transition matrix.\nxttrans AINEW\n\n\n\nxttrans\n\n\n\nlibrary(magrittr)\nHR.Data %>% \n  group_by(IDORIGIN) %>% \n  mutate(Lag.AI = lag(AINEW, 1)) %>%\n  ungroup() %$% \n  table(Lag.AI, AINEW) %>% prop.table(., 1)*100\n\n      AINEW\nLag.AI   1   2   3   4   5\n     1 100   0   0   0   0\n     2   0 100   0   0   0\n     3   0   0 100   0   0\n     4   0   0   0 100   0\n     5   0   0   0   0 100"
  },
  {
    "objectID": "posts/day-6/index.html",
    "href": "posts/day-6/index.html",
    "title": "Day 6: Panel Data",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation\n\nStarting the panel data, or the generalization to multiple time series, perhaps the most famous question in the generic literature is a question about fixed and random effects, more precisely, do we estimate specific unobserved constants or do we seek only the distribution of these constants. The implications of this basic issue are substantial."
  },
  {
    "objectID": "posts/day-6/index.html#some-simulated-data",
    "href": "posts/day-6/index.html#some-simulated-data",
    "title": "Day 6: Panel Data",
    "section": "Some Simulated Data",
    "text": "Some Simulated Data\nRandom effects and pooled regressions can be terribly wrong when the pooled and random effects moment condition fails. Let’s show some data here to illustrate the point. The true model here is \\[ y_{it} = \\alpha_{i} + X_{it}\\beta + \\epsilon_{it} \\] where the \\(\\beta=1\\) and \\(\\alpha_{i}=\\{6,0,-6\\}\\) and \\(\\epsilon \\sim \\mathcal{N}(0,1)\\). Here is the plot.\n\nX.FE <- c(seq(-2.5,-0.5,by=0.05),seq(-2,0,by=0.05),seq(-1.5,0.5,by=0.05))\ny.FE <- -3*c(rep(-2,41),rep(0,41),rep(2,41))+X.FE + rnorm(123,0,1)\nFE.data <- data.frame(y.FE,X.FE,unit=c(rep(1,41),rep(2,41),rep(3,41)), time=rep(seq(1,41,1),3))\nlibrary(foreign)\nwrite.dta(FE.data, \"FEData-2.dta\")\npar(mfrow=c(1,2))\nwith(FE.data, plot(X.FE,y.FE, bty=\"n\", main=\"Pooled\"))\nwith(FE.data, abline(lm(y.FE~X.FE), lty=2, col=\"brown\"))\nwith(FE.data, plot(X.FE,y.FE, bty=\"n\", col=unit, main=\"Fixed Effects\"))\nabline(a=-6,b=1, col=\"blue\")\nabline(a=0,b=1, col=\"blue\")\nabline(a=6,b=1, col=\"blue\")"
  },
  {
    "objectID": "posts/day-6/index.html#three-models",
    "href": "posts/day-6/index.html#three-models",
    "title": "Day 6: Panel Data",
    "section": "Three Models",
    "text": "Three Models\n\nlibrary(plm)\nFE.pdata <- pdata.frame(FE.data, c(\"unit\",\"time\"))\nmod.RE <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\")\nmod.RE2 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"amemiya\")\nmod.RE3 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"walhus\")\nmod.RE4 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"nerlove\")\nmod.FE <- plm(y.FE~X.FE, data=FE.pdata, model=\"within\")\nmod.pool <- plm(y.FE~X.FE, data=FE.pdata, model=\"pooling\")"
  },
  {
    "objectID": "posts/day-6/index.html#omitted-fixed-effects-can-be-very-bad",
    "href": "posts/day-6/index.html#omitted-fixed-effects-can-be-very-bad",
    "title": "Day 6: Panel Data",
    "section": "Omitted Fixed Effects can be Very Bad",
    "text": "Omitted Fixed Effects can be Very Bad\nAs we can see, the default random effects model in R [and Stata] is actually pretty horrible.\nlibrary(stargazer)\nstargazer(mod.RE,mod.RE2,mod.RE3,mod.RE4,mod.pool,mod.FE, type=\"html\", column.labels=c(\"RE\",\"RE-WalHus\",\"RE-Amemiya\",\"RE-Nerlove\",\"Pooled\",\"FE\"))\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\ny.FE\n\n\n\n\n\n\nRE\n\n\nRE-WalHus\n\n\nRE-Amemiya\n\n\nRE-Nerlove\n\n\nPooled\n\n\nFE\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n(3)\n\n\n(4)\n\n\n(5)\n\n\n(6)\n\n\n\n\n\n\n\n\nX.FE\n\n\n-2.852***\n\n\n1.043***\n\n\n0.968***\n\n\n1.045***\n\n\n-2.852***\n\n\n1.048***\n\n\n\n\n\n\n(0.528)\n\n\n(0.150)\n\n\n(0.173)\n\n\n(0.150)\n\n\n(0.528)\n\n\n(0.150)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n-4.039***\n\n\n-0.144\n\n\n-0.219\n\n\n-0.143\n\n\n-4.039***\n\n\n\n\n\n\n\n\n(0.650)\n\n\n(2.877)\n\n\n(0.884)\n\n\n(3.552)\n\n\n(0.650)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n123\n\n\n123\n\n\n123\n\n\n123\n\n\n123\n\n\n123\n\n\n\n\nR2\n\n\n0.194\n\n\n0.285\n\n\n0.206\n\n\n0.287\n\n\n0.194\n\n\n0.292\n\n\n\n\nAdjusted R2\n\n\n0.188\n\n\n0.279\n\n\n0.200\n\n\n0.281\n\n\n0.188\n\n\n0.274\n\n\n\n\nF Statistic\n\n\n29.156***\n\n\n48.135***\n\n\n31.412***\n\n\n48.722***\n\n\n29.156*** (df = 1; 121)\n\n\n49.015*** (df = 1; 119)\n\n\n\n\n\n\n\n\nNote:\n\n\np<0.1; p<0.05; p<0.01\n\n\n\n\n\nDiscussion\nThe random method matters quite a bit though; many of them are very close to the truth. Models containing much or all of the between information are wrong.\nIf the X and unit effects are dependent, then there are serious threats to proper inference."
  },
  {
    "objectID": "posts/day-7/index.html",
    "href": "posts/day-7/index.html",
    "title": "Day 7: Missing Data",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-10/index.html",
    "href": "posts/day-10/index.html",
    "title": "Day 10: Causal Inference in Panels and TWFE",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-9/index.html",
    "href": "posts/day-9/index.html",
    "title": "Day 9: GMM and GEE",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ESSSSDA22-3K",
    "section": "",
    "text": "panel data\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 19, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\npanel data\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 18, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\npanel data\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\npanel data\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 16, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\npanel data\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 15, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 12, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 11, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 10, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\npanel data\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 8, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n3K: Dynamics and Heterogeneity\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Harold D. Clarke was Ashbel Smith Professor in the School of Economic, Political and Policy Sciences, University of Texas at Dallas, and adjunct Professor, Department of Government, University of Essex. His current research interests focus on the political economy of party support. He has published widely on this topic in journals such as the American Journal of Political Science, American Political Science Review, and British Journal of Political Science. He is chief editor of Electoral Studies. He has been a principal investigator for the 2001, 2005 and 2010 British Election Study (University of Essex and University of Texas at Dallas), the 2011 Political Support in Canada Study, and the 2012 Political Support in America Study. His most recent books are Brexit—Why Britain Voted to Leave the European Union (Cambridge University Press, 2017), Affluence, Austerity and Electoral Change in Britain (Cambridge University Press, 2013), and Austerity and Political Choice in Britain (Palgrave Macmillan, 2015).\nRobert W. Walker is Associate Professor of Quantitative Methods in the Atkinson Graduate School of Management at Willamette University. He earned a Ph. D. in political science from the University of Rochester in 2005 and has previously held teaching positions at Dartmouth College, Rice University, Texas A&M University, and Washington University in Saint Louis. His current research develops and applies semi-Markov processes to time-series, cross-section data in international relations and international/comparative political economy. He teaches courses in quantitative methods/applied statistics and microeconomic strategy and previously taught four iterations in the U. S. National Science Foundation funded Empirical Implications of Theoretical Models sequence at Washington University in Saint Louis. His work with Curt Signorino and Muhammet Bas was awarded the Miller Prize for the best article in Political Analysis in 2009."
  }
]