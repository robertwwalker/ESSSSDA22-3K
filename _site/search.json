[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Harold D. Clarke was Ashbel Smith Professor in the School of Economic, Political and Policy Sciences, University of Texas at Dallas, and adjunct Professor, Department of Government, University of Essex. His current research interests focus on the political economy of party support. He has published widely on this topic in journals such as the American Journal of Political Science, American Political Science Review, and British Journal of Political Science. He is chief editor of Electoral Studies. He has been a principal investigator for the 2001, 2005 and 2010 British Election Study (University of Essex and University of Texas at Dallas), the 2011 Political Support in Canada Study, and the 2012 Political Support in America Study. His most recent books are Brexit—Why Britain Voted to Leave the European Union (Cambridge University Press, 2017), Affluence, Austerity and Electoral Change in Britain (Cambridge University Press, 2013), and Austerity and Political Choice in Britain (Palgrave Macmillan, 2015).\nRobert W. Walker is Associate Professor of Quantitative Methods in the Atkinson Graduate School of Management at Willamette University. He earned a Ph. D. in political science from the University of Rochester in 2005 and has previously held teaching positions at Dartmouth College, Rice University, Texas A&M University, and Washington University in Saint Louis. His current research develops and applies semi-Markov processes to time-series, cross-section data in international relations and international/comparative political economy. He teaches courses in quantitative methods/applied statistics and microeconomic strategy and previously taught four iterations in the U. S. National Science Foundation funded Empirical Implications of Theoretical Models sequence at Washington University in Saint Louis. His work with Curt Signorino and Muhammet Bas was awarded the Miller Prize for the best article in Political Analysis in 2009."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ESSSSDA22-3K",
    "section": "",
    "text": "time series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 12, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 11, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 10, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\ntime series\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nAug 8, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\n  \n\n\n\n\n\n3K: Dynamics and Heterogeneity\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nAug 3, 2022\n\n\nRobert W. Walker\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/arima-models/index.html#arima-models",
    "href": "posts/arima-models/index.html#arima-models",
    "title": "Simulation under ARIMA Models",
    "section": "ARIMA Models",
    "text": "ARIMA Models\nWe want to simulate data under an ARIMA (p, d, q) model. arima.sim wants inputs as a list where the expected length of the ar and ma vectors that will hold the actual values of the ar and ma parameters. Here, I ask for a series that is I(1) with a first-order ar=0.1 and a first-order ma=-0.5. Let me start by generating it and plotting the time series.\n\nlibrary(fpp3)\nn <- 100\nmy.data <- data.frame(\n  x=arima.sim(n = n, \n              model=list(order = c(1, 1, 1), ar=c(0.7), ma=c(-0.5)), n.start=20), \n  dtime = seq(1,n+1))\nlibrary(magrittr)\nmy.data %<>% as_tsibble(index=dtime) \nmy.data %>% autoplot() + labs(title=\"A (1, 1, 1) Series\", x=\"Time\")\n\n\n\n\nNow I want to display the ACF and PACF in levels.\n\nlibrary(patchwork)\n{my.data %>% ACF(x, lag_max=20) %>% \n    autoplot() } + \n  {my.data %>% PACF(x, lag_max=20) %>% \n      autoplot() }\n\n\n\n\nFinally, let me display the ACF and PACF with differenced data.\n\n{my.data %>% ACF(diff(x), lag_max=20) %>% \n    autoplot() } + \n  {my.data %>% PACF(diff(x), lag_max=20) %>% \n      autoplot() }"
  },
  {
    "objectID": "posts/day-1/index.html",
    "href": "posts/day-1/index.html",
    "title": "Day 1",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-1/index.html#basic-r-commands",
    "href": "posts/day-1/index.html#basic-r-commands",
    "title": "Day 1",
    "section": "Basic R commands",
    "text": "Basic R commands\n\nlibrary(haven); library(kableExtra)\nHR.Data <- read_dta(url(\"https://github.com/robertwwalker/DADMStuff/raw/master/ISQ99-Essex.dta\"))\nlibrary(skimr)\nskim(HR.Data) %>% kable() %>% scroll_box(width=\"80%\", height=\"50%\")\n\n\n\n \n  \n    skim_type \n    skim_variable \n    n_missing \n    complete_rate \n    numeric.mean \n    numeric.sd \n    numeric.p0 \n    numeric.p25 \n    numeric.p50 \n    numeric.p75 \n    numeric.p100 \n    numeric.hist \n  \n \n\n  \n    numeric \n    IDORIGIN \n    0 \n    1.0000000 \n    446.7178771 \n    243.1931782 \n    2.00 \n    290.000 \n    435.000 \n    640.00 \n    990.00 \n    ▆▇▇▆▂ \n  \n  \n    numeric \n    YEAR \n    0 \n    1.0000000 \n    1984.5000000 \n    5.1889328 \n    1976.00 \n    1980.000 \n    1984.500 \n    1989.00 \n    1993.00 \n    ▇▆▇▆▇ \n  \n  \n    numeric \n    AI \n    1061 \n    0.6707014 \n    2.7533549 \n    1.0752989 \n    1.00 \n    2.000 \n    3.000 \n    3.00 \n    5.00 \n    ▃▇▇▃▂ \n  \n  \n    numeric \n    SD \n    587 \n    0.8178150 \n    2.2406072 \n    1.1303528 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▆▂▁ \n  \n  \n    numeric \n    POLRT \n    382 \n    0.8814401 \n    3.8095070 \n    2.2230297 \n    1.00 \n    2.000 \n    3.000 \n    6.00 \n    7.00 \n    ▇▂▂▁▇ \n  \n  \n    numeric \n    MIL2 \n    382 \n    0.8814401 \n    0.2725352 \n    0.4453421 \n    0.00 \n    0.000 \n    0.000 \n    1.00 \n    1.00 \n    ▇▁▁▁▃ \n  \n  \n    numeric \n    LEFT \n    393 \n    0.8780261 \n    0.1763874 \n    0.3812168 \n    0.00 \n    0.000 \n    0.000 \n    0.00 \n    1.00 \n    ▇▁▁▁▂ \n  \n  \n    numeric \n    BRIT \n    290 \n    0.9099938 \n    0.3553888 \n    0.4787126 \n    0.00 \n    0.000 \n    0.000 \n    1.00 \n    1.00 \n    ▇▁▁▁▅ \n  \n  \n    numeric \n    PCGNP \n    443 \n    0.8625078 \n    3591.6509536 \n    5698.3554010 \n    52.00 \n    390.000 \n    1112.000 \n    3510.00 \n    36670.00 \n    ▇▁▁▁▁ \n  \n  \n    numeric \n    AINEW \n    468 \n    0.8547486 \n    2.4433551 \n    1.1558005 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▇▃▂ \n  \n  \n    numeric \n    SDNEW \n    468 \n    0.8547486 \n    2.2618010 \n    1.1365604 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▆▂▁ \n  \n  \n    numeric \n    IDGURR \n    0 \n    1.0000000 \n    455.7709497 \n    246.5201369 \n    2.00 \n    290.000 \n    450.000 \n    663.00 \n    990.00 \n    ▆▇▇▇▃ \n  \n  \n    numeric \n    AILAG \n    644 \n    0.8001241 \n    2.4499612 \n    1.1479673 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▇▃▂ \n  \n  \n    numeric \n    SDLAG \n    644 \n    0.8001241 \n    2.2470908 \n    1.1156632 \n    1.00 \n    1.000 \n    2.000 \n    3.00 \n    5.00 \n    ▇▇▆▂▁ \n  \n  \n    numeric \n    PERCHPCG \n    618 \n    0.8081937 \n    4.6138441 \n    13.2208934 \n    -95.50 \n    -2.545 \n    4.615 \n    11.76 \n    128.57 \n    ▁▂▇▁▁ \n  \n  \n    numeric \n    PERCHPOP \n    293 \n    0.9090627 \n    2.1928815 \n    4.0424128 \n    -48.45 \n    0.910 \n    2.220 \n    2.94 \n    126.01 \n    ▁▇▁▁▁ \n  \n  \n    numeric \n    LPOP \n    115 \n    0.9643079 \n    15.4819279 \n    1.8633316 \n    11.00 \n    14.510 \n    15.590 \n    16.64 \n    20.89 \n    ▂▃▇▃▁ \n  \n  \n    numeric \n    PCGTHOU \n    443 \n    0.8625078 \n    3.5916985 \n    5.6983334 \n    0.05 \n    0.390 \n    1.110 \n    3.51 \n    36.67 \n    ▇▁▁▁▁ \n  \n  \n    numeric \n    DEMOC3 \n    793 \n    0.7538796 \n    3.6817620 \n    4.3577178 \n    0.00 \n    0.000 \n    0.000 \n    9.00 \n    10.00 \n    ▇▁▁▂▃ \n  \n  \n    numeric \n    CWARCOW \n    407 \n    0.8736809 \n    0.0920071 \n    0.2890873 \n    0.00 \n    0.000 \n    0.000 \n    0.00 \n    1.00 \n    ▇▁▁▁▁ \n  \n  \n    numeric \n    IWARCOW2 \n    380 \n    0.8820608 \n    0.0862069 \n    0.2807187 \n    0.00 \n    0.000 \n    0.000 \n    0.00 \n    1.00 \n    ▇▁▁▁▁"
  },
  {
    "objectID": "posts/day-1/index.html#more-r-summary",
    "href": "posts/day-1/index.html#more-r-summary",
    "title": "Day 1",
    "section": "More R summary",
    "text": "More R summary\nA little function that I wrote up on github.\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()     masks stats::filter()\n✖ dplyr::group_rows() masks kableExtra::group_rows()\n✖ dplyr::lag()        masks stats::lag()\n\nlibrary(plm)\n\n\nAttaching package: 'plm'\n\nThe following objects are masked from 'package:dplyr':\n\n    between, lag, lead\n\nsource(url(\"https://raw.githubusercontent.com/robertwwalker/DADMStuff/master/xtsum.R\"))\n# Be careful with the ID variable, the safest is to make it factor; this can go wildly wrong\nxtsum(IDORIGIN~., data=HR.Data) %>% kable() %>% scroll_box(width=\"80%\", height=\"50%\")\n\nNote: Using an external vector in selections is ambiguous.\nℹ Use `all_of(unit)` instead of `unit` to silence this message.\nℹ See <https://tidyselect.r-lib.org/reference/faq-external-vector.html>.\nThis message is displayed once per session.\n\n\n\n\n \n  \n      \n    O.mean \n    O.sd \n    O.min \n    O.max \n    O.SumSQ \n    O.N \n    B.mean \n    B.sd \n    B.min \n    B.max \n    B.Units \n    B.t.bar \n    W.sd \n    W.min \n    W.max \n    W.SumSQ \n    Within.Ovr.Ratio \n  \n \n\n  \n    YEAR \n    1984.5 \n    5.189 \n    1976 \n    1993 \n    86725.5 \n    3222 \n    1984.5 \n    0 \n    1984.5 \n    1984.5 \n    179 \n    18 \n    5.189 \n    -8.5 \n    8.5 \n    86725.5 \n    1 \n  \n  \n    AI \n    2.753 \n    1.075 \n    1 \n    5 \n    2497.538 \n    2161 \n    2.498 \n    0.989 \n    1 \n    5 \n    173 \n    12.491 \n    0.631 \n    -2.375 \n    2.5625 \n    860.822 \n    0.345 \n  \n  \n    SD \n    2.241 \n    1.13 \n    1 \n    5 \n    3365.455 \n    2635 \n    2.241 \n    1.004 \n    1 \n    5 \n    178 \n    14.803 \n    0.624 \n    -2.666667 \n    3.0625 \n    1025.695 \n    0.305 \n  \n  \n    POLRT \n    3.81 \n    2.223 \n    1 \n    7 \n    14029.94 \n    2840 \n    3.78 \n    1.99 \n    1 \n    7 \n    179 \n    15.866 \n    0.925 \n    -4 \n    4.777778 \n    2428.552 \n    0.173 \n  \n  \n    MIL2 \n    0.273 \n    0.445 \n    0 \n    1 \n    563.058 \n    2840 \n    0.24 \n    0.377 \n    0 \n    1 \n    179 \n    15.866 \n    0.216 \n    -0.9444444 \n    0.8888889 \n    132.778 \n    0.236 \n  \n  \n    LEFT \n    0.176 \n    0.381 \n    0 \n    1 \n    410.983 \n    2829 \n    0.157 \n    0.334 \n    0 \n    1 \n    179 \n    15.804 \n    0.157 \n    -0.8888889 \n    0.8888889 \n    69.611 \n    0.169 \n  \n  \n    BRIT \n    0.355 \n    0.479 \n    0 \n    1 \n    671.685 \n    2932 \n    0.335 \n    0.473 \n    0 \n    1 \n    179 \n    16.38 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    PCGNP \n    3591.651 \n    5698.355 \n    52 \n    36670 \n    90205144379 \n    2779 \n    3449.178 \n    5049.297 \n    112.2222 \n    22653.89 \n    173 \n    16.064 \n    2278.412 \n    -12303.33 \n    16961.67 \n    14421042273 \n    0.16 \n  \n  \n    AINEW \n    2.443 \n    1.156 \n    1 \n    5 \n    3677.663 \n    2754 \n    2.379 \n    1.012 \n    1 \n    5 \n    178 \n    15.472 \n    0.622 \n    -2.388889 \n    2.944444 \n    1064.102 \n    0.289 \n  \n  \n    SDNEW \n    2.262 \n    1.137 \n    1 \n    5 \n    3556.241 \n    2754 \n    2.253 \n    1.006 \n    1 \n    5 \n    178 \n    15.472 \n    0.631 \n    -2.588235 \n    3 \n    1096.442 \n    0.308 \n  \n  \n    IDGURR \n    455.771 \n    246.52 \n    2 \n    990 \n    195747185 \n    3222 \n    455.771 \n    247.173 \n    2 \n    990 \n    179 \n    18 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    AILAG \n    2.45 \n    1.148 \n    1 \n    5 \n    3396.045 \n    2578 \n    2.402 \n    1.039 \n    1 \n    5 \n    177 \n    14.565 \n    0.609 \n    -2.411765 \n    3 \n    955.37 \n    0.281 \n  \n  \n    SDLAG \n    2.247 \n    1.116 \n    1 \n    5 \n    3207.603 \n    2578 \n    2.236 \n    0.991 \n    1 \n    5 \n    177 \n    14.565 \n    0.608 \n    -2.5 \n    3.058824 \n    952.174 \n    0.297 \n  \n  \n    PERCHPCG \n    4.614 \n    13.221 \n    -95.5 \n    128.57 \n    454983.6 \n    2604 \n    3.325 \n    6.893 \n    -36.21333 \n    15.03765 \n    168 \n    15.5 \n    12.393 \n    -92.50235 \n    114.8882 \n    399763 \n    0.879 \n  \n  \n    PERCHPOP \n    2.193 \n    4.042 \n    -48.45 \n    126.01 \n    47846.75 \n    2929 \n    2.842 \n    9.443 \n    -2.126471 \n    126.01 \n    176 \n    16.642 \n    3.018 \n    -48.12235 \n    80.69765 \n    26663.59 \n    0.557 \n  \n  \n    LPOP \n    15.482 \n    1.863 \n    11 \n    20.89 \n    10784.05 \n    3107 \n    15.488 \n    1.844 \n    11.09056 \n    20.76889 \n    177 \n    17.554 \n    0.129 \n    -0.7288889 \n    0.7311111 \n    51.883 \n    0.005 \n  \n  \n    PCGTHOU \n    3.592 \n    5.698 \n    0.05 \n    36.67 \n    90204.45 \n    2779 \n    3.449 \n    5.049 \n    0.1122222 \n    22.65389 \n    173 \n    16.064 \n    2.278 \n    -12.30333 \n    16.96167 \n    14420.95 \n    0.16 \n  \n  \n    DEMOC3 \n    3.682 \n    4.358 \n    0 \n    10 \n    46107 \n    2429 \n    3.774 \n    3.96 \n    0 \n    10 \n    155 \n    15.671 \n    1.726 \n    -7.277778 \n    7.941176 \n    7229.815 \n    0.157 \n  \n  \n    CWARCOW \n    0.092 \n    0.289 \n    0 \n    1 \n    235.17 \n    2815 \n    0.095 \n    0.245 \n    0 \n    1 \n    179 \n    15.726 \n    0.175 \n    -0.8888889 \n    0.9444444 \n    85.693 \n    0.364 \n  \n  \n    IWARCOW2 \n    0.086 \n    0.281 \n    0 \n    1 \n    223.879 \n    2842 \n    0.092 \n    0.227 \n    0 \n    1 \n    179 \n    15.877 \n    0.19 \n    -0.8888889 \n    0.9444444 \n    102.992 \n    0.46"
  },
  {
    "objectID": "posts/day-1/index.html#the-core-idea",
    "href": "posts/day-1/index.html#the-core-idea",
    "title": "Day 1",
    "section": "The Core Idea",
    "text": "The Core Idea\nIn R, this is an essential group_by calculation in the tidyverse. The within data is the overall data with group means subtracted.\n\nHR.Data %>% \n  group_by(IDORIGIN) %>% \n  mutate(DEMOC.Centered = \n           DEMOC3 - mean(DEMOC3, na.rm=TRUE)) %>%\n  filter(IDORIGIN==42) %>% \n  select(IDORIGIN, YEAR, DEMOC3, DEMOC.Centered) \n\n# A tibble: 18 × 4\n# Groups:   IDORIGIN [1]\n   IDORIGIN  YEAR DEMOC3 DEMOC.Centered\n      <dbl> <dbl>  <dbl>          <dbl>\n 1       42  1976      1         -5.11 \n 2       42  1977      1         -5.11 \n 3       42  1978      6         -0.111\n 4       42  1979      6         -0.111\n 5       42  1980      6         -0.111\n 6       42  1981      6         -0.111\n 7       42  1982      7          0.889\n 8       42  1983      7          0.889\n 9       42  1984      7          0.889\n10       42  1985      7          0.889\n11       42  1986      7          0.889\n12       42  1987      7          0.889\n13       42  1988      7          0.889\n14       42  1989      7          0.889\n15       42  1990      7          0.889\n16       42  1991      7          0.889\n17       42  1992      7          0.889\n18       42  1993      7          0.889\n\n\nIn Stata, the key is to first load and declare the data.\nuse \"https://github.com/robertwwalker/Essex-Data/raw/main/ISQ99-Essex.dta\"\ndes\n\n\n\nStata Load\n\n\nxtset denotes two key features of the data, the \\(i\\) and \\(t\\).\nxtset IDORIGIN YEAR\n\n\n\nxtset\n\n\nStata has internal capabilities for summarising and describing xt data. A between and within summary is given by xtsum\nxtsum\n\n\n\nxtsum\n\n\nThe description can be deceptive because the indices are a complete grid.\nxtdes\n\n\n\nxtdes"
  },
  {
    "objectID": "posts/day-1/index.html#qualitative-variables",
    "href": "posts/day-1/index.html#qualitative-variables",
    "title": "Day 1",
    "section": "Qualitative Variables",
    "text": "Qualitative Variables\n\nxttab\n\nBetween: How many units received each category?\nWithin: Of all observations of units that received that category at least once, what percent of observations take this value?\n\nxttab AINEW\n\n\n\nxttab\n\n\n\n\nThe Between\n\nbetween.tally <- function(x) {\nHR.Data %>% select(IDORIGIN, AINEW) %>% filter(AINEW==x) %$% table(IDORIGIN) %>% length()\n}\nsapply(c(1:5), function(x) {between.tally(x)})\n\n[1]  96 121 113  86  43\n\n\n\n\nxttrans\nA first-order transition matrix.\nxttrans AINEW\n\n\n\nxttrans\n\n\n\nlibrary(magrittr)\nHR.Data %>% \n  group_by(IDORIGIN) %>% \n  mutate(Lag.AI = lag(AINEW, 1)) %>%\n  ungroup() %$% \n  table(Lag.AI, AINEW) %>% prop.table(., 1)*100\n\n      AINEW\nLag.AI   1   2   3   4   5\n     1 100   0   0   0   0\n     2   0 100   0   0   0\n     3   0   0 100   0   0\n     4   0   0   0 100   0\n     5   0   0   0   0 100"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Digital Resources\nDepending upon your software of choice, you will want to have a look over the relevant manuals. - For Stata ts and xt - For R there is timetk and fpp3 and plm along with panelr. - A github with the course data. - A github with this website. - Robert W. Walker’s website"
  },
  {
    "objectID": "posts/day-2/index.html",
    "href": "posts/day-2/index.html",
    "title": "Day 2",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-2/index.html#basic-r-commands",
    "href": "posts/day-2/index.html#basic-r-commands",
    "title": "Day 2",
    "section": "Basic R commands",
    "text": "Basic R commands\nThe first key will be to specify date/time formats. The list of available formats is quite large, thankfully, there are unified tools."
  },
  {
    "objectID": "posts/spurious-regressions/index.html#an-example-of-time-series-troubles",
    "href": "posts/spurious-regressions/index.html#an-example-of-time-series-troubles",
    "title": "Spurious Regressions among I(1) Variables",
    "section": "An Example of Time Series Troubles",
    "text": "An Example of Time Series Troubles\nLet me do this with a relatively simple regression. Two variables:\n\\[ y = \\alpha + \\beta x + \\epsilon \\]\nBoth are generated randomly. Here’s a basic plot.\n\ny <- cumsum(rnorm(100))\nx <- cumsum(rnorm(100))\nplot(x=seq(1:100), y=y, type=\"l\", col=\"red\", ylim=c(-15,15))\nlines(x=seq(1:100), y=x, col=\"blue\")\n\n\n\n\nEach time series contains 100 observations. Because both x and y are random, the slopes should be 0, 95% of the time with 95% confidence because there is no underlying relationship. In practice, let’s look at the distribution of p-values for the probability of no relationship.\n\nSR <- function(n) {\n  Results <- NULL\n  for(i in 1:n) {\ny <- cumsum(rnorm(100))\nx <- cumsum(rnorm(100))\nResult <- summary(lm(y~x))$coefficients[2,4]\nResults <- append(Result,Results)\n  }\n  Results\n}\n\nI replicate the process of random x and random y 1000 times and show the p-values below. Because they are random, approximately 95% should be greater than 0.05.\n\nRes1 <- SR(1000)\nplot(density(Res1), main=\"Distribution of p-values from Trending x\")\n\n\n\n\nIn practice,\n\ntable(Res1 > 0.05)\n\n\nFALSE  TRUE \n  752   248 \n\n\nThe above table should show about 950 TRUE and 50 FALSE but because each is trended and they share variation from trend, the actual frequency of rejecting the claim of no relationship is far more common than 5%."
  },
  {
    "objectID": "posts/day-3/index.html",
    "href": "posts/day-3/index.html",
    "title": "Day 3",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-5/index.html",
    "href": "posts/day-5/index.html",
    "title": "Day 5",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  },
  {
    "objectID": "posts/day-4/index.html",
    "href": "posts/day-4/index.html",
    "title": "Day 4",
    "section": "",
    "text": "Slides in .pdf format\nA xaringan for presentation"
  }
]