{
  "hash": "34dd8278db65b0fb79f53fdef9a9f0da",
  "result": {
    "markdown": "---\ntitle: \"Day 6: Panel Data\"\nauthor: \"Robert W. Walker\"\ndate: \"08/15/2022\"\ncategories: [panel data, code, analysis]\nimage: \"image.png\"\n---\n\n\n## Slides\n\n- [Slides in .pdf format](./img/slidesDay6.pdf)\n- [A xaringan for presentation](https://robertwwalker.github.io/xaringan/ESSSSDA22-Day6/)\n\n## `panelr`\n\n[The panelr package vignette on between-within](https://cran.r-project.org/web/packages/panelr/vignettes/wbm.html)\n\nStarting the panel data, or the generalization to multiple time series, perhaps the most famous question in the generic literature is a question about fixed and random effects, more precisely, do we estimate specific unobserved constants or do we seek only the distribution of these constants.  The implications of this basic issue are substantial.\n\n## Some Simulated Data\n\nRandom effects and pooled regressions can be terribly wrong when the pooled and random effects moment condition fails.  Let's show some data here to illustrate the point.  The true model here is $$ y_{it} = \\alpha_{i} + X_{it}\\beta + \\epsilon_{it} $$ where the $\\beta=1$ and $\\alpha_{i}=\\{6,0,-6\\}$ and $\\epsilon \\sim \\mathcal{N}(0,1)$.  Here is the plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX.FE <- c(seq(-2.5,-0.5,by=0.05),seq(-2,0,by=0.05),seq(-1.5,0.5,by=0.05))\ny.FE <- -3*c(rep(-2,41),rep(0,41),rep(2,41))+X.FE + rnorm(123,0,1)\nFE.data <- data.frame(y.FE,X.FE,unit=c(rep(1,41),rep(2,41),rep(3,41)), time=rep(seq(1,41,1),3))\nlibrary(foreign)\nwrite.dta(FE.data, \"FEData-2.dta\")\npar(mfrow=c(1,2))\nwith(FE.data, plot(X.FE,y.FE, bty=\"n\", main=\"Pooled\"))\nwith(FE.data, abline(lm(y.FE~X.FE), lty=2, col=\"brown\"))\nwith(FE.data, plot(X.FE,y.FE, bty=\"n\", col=unit, main=\"Fixed Effects\"))\nabline(a=-6,b=1, col=\"blue\")\nabline(a=0,b=1, col=\"blue\")\nabline(a=6,b=1, col=\"blue\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/SimData-1.png){width=672}\n:::\n:::\n\n\n## Three Models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plm)\nFE.pdata <- pdata.frame(FE.data, c(\"unit\",\"time\"))\nmod.RE <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\")\nmod.RE2 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"amemiya\")\nmod.RE3 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"walhus\")\nmod.RE4 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"nerlove\")\nmod.FE <- plm(y.FE~X.FE, data=FE.pdata, model=\"within\")\nmod.pool <- plm(y.FE~X.FE, data=FE.pdata, model=\"pooling\")\n```\n:::\n\n\n## Omitted Fixed Effects can be Very Bad\n\nAs we can see, the default random effects model in R [and Stata] is actually pretty horrible.  \n\n\n\n```{.r .cell-code}\nlibrary(stargazer)\nstargazer(mod.RE,mod.RE2,mod.RE3,mod.RE4,mod.pool,mod.FE, type=\"html\", column.labels=c(\"RE\",\"RE-WalHus\",\"RE-Amemiya\",\"RE-Nerlove\",\"Pooled\",\"FE\"))\n```\n\n\n<table style=\"text-align:center\"><tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"6\"><em>Dependent variable:</em></td></tr>\n<tr><td></td><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n<tr><td style=\"text-align:left\"></td><td colspan=\"6\">y.FE</td></tr>\n<tr><td style=\"text-align:left\"></td><td>RE</td><td>RE-WalHus</td><td>RE-Amemiya</td><td>RE-Nerlove</td><td>Pooled</td><td>FE</td></tr>\n<tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td></tr>\n<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">X.FE</td><td>-3.043<sup>***</sup></td><td>0.837<sup>***</sup></td><td>0.764<sup>***</sup></td><td>0.839<sup>***</sup></td><td>-3.043<sup>***</sup></td><td>0.842<sup>***</sup></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.524)</td><td>(0.140)</td><td>(0.164)</td><td>(0.139)</td><td>(0.524)</td><td>(0.140)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>\n<tr><td style=\"text-align:left\">Constant</td><td>-4.084<sup>***</sup></td><td>-0.203</td><td>-0.277</td><td>-0.202</td><td>-4.084<sup>***</sup></td><td></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.646)</td><td>(2.866)</td><td>(0.845)</td><td>(3.538)</td><td>(0.646)</td><td></td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>\n<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Observations</td><td>123</td><td>123</td><td>123</td><td>123</td><td>123</td><td>123</td></tr>\n<tr><td style=\"text-align:left\">R<sup>2</sup></td><td>0.218</td><td>0.228</td><td>0.153</td><td>0.230</td><td>0.218</td><td>0.234</td></tr>\n<tr><td style=\"text-align:left\">Adjusted R<sup>2</sup></td><td>0.211</td><td>0.222</td><td>0.146</td><td>0.224</td><td>0.211</td><td>0.215</td></tr>\n<tr><td style=\"text-align:left\">F Statistic</td><td>33.666<sup>***</sup></td><td>35.758<sup>***</sup></td><td>21.821<sup>***</sup></td><td>36.205<sup>***</sup></td><td>33.666<sup>***</sup> (df = 1; 121)</td><td>36.446<sup>***</sup> (df = 1; 119)</td></tr>\n<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"><em>Note:</em></td><td colspan=\"6\" style=\"text-align:right\"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>\n</table>\n\n\n### Discussion\n\nThe random method matters quite a bit though; many of them are very close to the truth. Models containing much or all of the between information are wrong.  \n\nIf the X and unit effects are dependent, then there are serious threats to proper inference.\n\n\n## `plm` things\n\nBeck and Katz (1995) standard errors are provided with `vcovBK()`.  The key argument is `cluster` which averages over groups or time.  The Beck and Katz paper would involve `cluster=\"time\"`.\n\n**Almost all panel unit root testing goes on with `purtest`.  The `test=` argument is key for IPS, Levin, et al., Maddala-Wu, Hadri, and various tests proposed by Choi (2001).**  A few others are specified individually below.\n\n- The test of serial correlation for panel models is given by `pbgtest(model)`.\n\n- The Baltagi and Li test of serial correlation in panel models with random effects is given by `pbltest(model)`.  The various alternatives are specified in `alternative`.\n\n- The Baltagi-Wu statistic for AR(1) disturbances is given by `pbnftest(model, test=\"lbi\")` while a BNF (1982) statistic is the default for this test for fixed effects models.\n\n```\n# replicate Baltagi (2013), p. 101, table 5.1:\nre <- plm(inv ~ value + capital, data = Grunfeld, model = \"random\")\npbnftest(re, test = \"lbi\")\n```\n\n- `pbsytest(model)` gives the joint test of Baltagi and Li and a variant owing to Bera, et. al (2001) and Sosa-Escudero and Bera (2008) -- the latter is a paper in Stata journal with companion software to be installed.\n\n- `pcdtest(formula, data)` gives the Pesaran test for cross-sectional dependence.\n\n- `pdwtest(model)` gives a panel Durbin-Watson statistic.\n\n- `pFtest` gives the F-test of fixed effects.\n\n- `pggls` gives GLS estimators for panel data specifying the effect and a model of `within, pooling, fd`.\n\n- `phansitest(purtest object)` combines unit root tests in the method proposed by Hanck (2013).\n\n- `phtest(model1, model2)` is the Hausman test for panel data models.  This one has robust options detailed in the last section of `?phtest`.\n\n- `piest(formula, data)` performs Chamberlain's tests on the `within` regression.\n\n- Another test of unit/time effects is given in `plmtest()`.\n\n- Chow tests of `poolability` are given by `pooltest()` applied to a pooled or within regression.\n\n- `pvar` ensures variation along dimensions.\n\n- `pvcm` will estimate variable coefficients models ala Swamy (1970).\n\n- Joint tests of coefficients are constructed using `pwaldtest`.\n\n- Wooldridge's test for serial correlation in `within` models is `pwartest(model)`\n\n- Wooldridge's test for AR(1) errors  in level or differenced panel models is given by `pwfdtest(model)`.  The underlying idea is clever; if the levels are independent then the errors in first-differences will be correlated as -0.5.  The test can be implemented against either within/fe or first-difference alternatives.\n\n- `pwtest(pooling model)` gives a semi-parametric test for the presence of (individual or time) unobserved effects in panel models that owes to Wooldridge.\n\n- `ranef` and `fixef` extract the random and fixed effects, respectively.\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}