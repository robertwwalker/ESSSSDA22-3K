{
  "hash": "861c64dd45b56979646a4c4276a52be0",
  "result": {
    "markdown": "---\ntitle: \"Day 6: Panel Data\"\nauthor: \"Robert W. Walker\"\ndate: \"08/15/2022\"\ncategories: [panel data, code, analysis]\nimage: \"image.png\"\n---\n\n\n## Slides\n\n- [Slides in .pdf format](./img/slidesDay6.pdf)\n- [A xaringan for presentation](https://robertwwalker.github.io/xaringan/ESSSSDA22-Day6/)\n\n## `panelr`\n\n[The panelr package vignette on between-within](https://cran.r-project.org/web/packages/panelr/vignettes/wbm.html)\n\nStarting the panel data, or the generalization to multiple time series, perhaps the most famous question in the generic literature is a question about fixed and random effects, more precisely, do we estimate specific unobserved constants or do we seek only the distribution of these constants.  The implications of this basic issue are substantial.\n\n## Some Simulated Data\n\nRandom effects and pooled regressions can be terribly wrong when the pooled and random effects moment condition fails.  Let's show some data here to illustrate the point.  The true model here is $$ y_{it} = \\alpha_{i} + X_{it}\\beta + \\epsilon_{it} $$ where the $\\beta=1$ and $\\alpha_{i}=\\{6,0,-6\\}$ and $\\epsilon \\sim \\mathcal{N}(0,1)$.  Here is the plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX.FE <- c(seq(-2.5,-0.5,by=0.05),seq(-2,0,by=0.05),seq(-1.5,0.5,by=0.05))\ny.FE <- -3*c(rep(-2,41),rep(0,41),rep(2,41))+X.FE + rnorm(123,0,1)\nFE.data <- data.frame(y.FE,X.FE,unit=c(rep(1,41),rep(2,41),rep(3,41)), time=rep(seq(1,41,1),3))\nlibrary(foreign)\nwrite.dta(FE.data, \"FEData-2.dta\")\npar(mfrow=c(1,2))\nwith(FE.data, plot(X.FE,y.FE, bty=\"n\", main=\"Pooled\"))\nwith(FE.data, abline(lm(y.FE~X.FE), lty=2, col=\"brown\"))\nwith(FE.data, plot(X.FE,y.FE, bty=\"n\", col=unit, main=\"Fixed Effects\"))\nabline(a=-6,b=1, col=\"blue\")\nabline(a=0,b=1, col=\"blue\")\nabline(a=6,b=1, col=\"blue\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/SimData-1.png){width=672}\n:::\n:::\n\n\n## Three Models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plm)\nFE.pdata <- pdata.frame(FE.data, c(\"unit\",\"time\"))\nmod.RE <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\")\nmod.RE2 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"amemiya\")\nmod.RE3 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"walhus\")\nmod.RE4 <- plm(y.FE~X.FE, data=FE.pdata, model=\"random\", random.method = \"nerlove\")\nmod.FE <- plm(y.FE~X.FE, data=FE.pdata, model=\"within\")\nmod.pool <- plm(y.FE~X.FE, data=FE.pdata, model=\"pooling\")\n```\n:::\n\n\n## Omitted Fixed Effects can be Very Bad\n\nAs we can see, the default random effects model in R [and Stata] is actually pretty horrible.  \n\n\n\n```{.r .cell-code}\nlibrary(stargazer)\nstargazer(mod.RE,mod.RE2,mod.RE3,mod.RE4,mod.pool,mod.FE, type=\"html\", column.labels=c(\"RE\",\"RE-WalHus\",\"RE-Amemiya\",\"RE-Nerlove\",\"Pooled\",\"FE\"))\n```\n\n\n<table style=\"text-align:center\"><tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"></td><td colspan=\"6\"><em>Dependent variable:</em></td></tr>\n<tr><td></td><td colspan=\"6\" style=\"border-bottom: 1px solid black\"></td></tr>\n<tr><td style=\"text-align:left\"></td><td colspan=\"6\">y.FE</td></tr>\n<tr><td style=\"text-align:left\"></td><td>RE</td><td>RE-WalHus</td><td>RE-Amemiya</td><td>RE-Nerlove</td><td>Pooled</td><td>FE</td></tr>\n<tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td><td>(5)</td><td>(6)</td></tr>\n<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">X.FE</td><td>-2.953<sup>***</sup></td><td>0.980<sup>***</sup></td><td>0.903<sup>***</sup></td><td>0.982<sup>***</sup></td><td>-2.953<sup>***</sup></td><td>0.986<sup>***</sup></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.536)</td><td>(0.166)</td><td>(0.188)</td><td>(0.166)</td><td>(0.536)</td><td>(0.166)</td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>\n<tr><td style=\"text-align:left\">Constant</td><td>-4.046<sup>***</sup></td><td>-0.113</td><td>-0.190</td><td>-0.111</td><td>-4.046<sup>***</sup></td><td></td></tr>\n<tr><td style=\"text-align:left\"></td><td>(0.661)</td><td>(2.907)</td><td>(0.947)</td><td>(3.588)</td><td>(0.661)</td><td></td></tr>\n<tr><td style=\"text-align:left\"></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>\n<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\">Observations</td><td>123</td><td>123</td><td>123</td><td>123</td><td>123</td><td>123</td></tr>\n<tr><td style=\"text-align:left\">R<sup>2</sup></td><td>0.200</td><td>0.223</td><td>0.161</td><td>0.225</td><td>0.200</td><td>0.229</td></tr>\n<tr><td style=\"text-align:left\">Adjusted R<sup>2</sup></td><td>0.194</td><td>0.216</td><td>0.154</td><td>0.218</td><td>0.194</td><td>0.210</td></tr>\n<tr><td style=\"text-align:left\">F Statistic</td><td>30.307<sup>***</sup></td><td>34.648<sup>***</sup></td><td>23.174<sup>***</sup></td><td>35.106<sup>***</sup></td><td>30.307<sup>***</sup> (df = 1; 121)</td><td>35.386<sup>***</sup> (df = 1; 119)</td></tr>\n<tr><td colspan=\"7\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align:left\"><em>Note:</em></td><td colspan=\"6\" style=\"text-align:right\"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>\n</table>\n\n\n### Discussion\n\nThe random method matters quite a bit though; many of them are very close to the truth. Models containing much or all of the between information are wrong.  \n\nIf the X and unit effects are dependent, then there are serious threats to proper inference.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}